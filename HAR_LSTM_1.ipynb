{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uclkism015wr"
   },
   "outputs": [],
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "giik95fp3N9I",
    "outputId": "4b05a9a3-e9ae-4a05-c4a9-98d949315b9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# This will prompt for authorization.\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7zjvT3EN3fP4",
    "outputId": "f17bdb9e-f95a-495d-a821-5b2f6ef9f758"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAR_EDA.ipynb  HAR_LSTM.ipynb  HAR_PREDICTION_MODELS.ipynb  UCI_HAR_Dataset\n"
     ]
    }
   ],
   "source": [
    "!ls \"/content/drive/My Drive/Colab Notebooks/HumanActivityRecognition/HAR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cXKwAYpJ15xe"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oIQaIl5f15x8"
   },
   "outputs": [],
   "source": [
    "# Activities are the class labels\n",
    "# It is a 6 class classification\n",
    "ACTIVITIES = {\n",
    "    0: 'WALKING',\n",
    "    1: 'WALKING_UPSTAIRS',\n",
    "    2: 'WALKING_DOWNSTAIRS',\n",
    "    3: 'SITTING',\n",
    "    4: 'STANDING',\n",
    "    5: 'LAYING',\n",
    "}\n",
    "\n",
    "# Utility function to print the confusion matrix\n",
    "def confusion_matrix(Y_true, Y_pred):\n",
    "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "\n",
    "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "isgtjz0115ye"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2rS6EBKf15yi"
   },
   "outputs": [],
   "source": [
    "# Data directory\n",
    "DATADIR = '/content/drive/My Drive/Colab Notebooks/HumanActivityRecognition/HAR/UCI_HAR_Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ahh5-UWO15zN"
   },
   "outputs": [],
   "source": [
    "# Raw data signals\n",
    "# Signals are from Accelerometer and Gyroscope\n",
    "# The signals are in x,y,z directions\n",
    "# Sensor signals are filtered to have only body acceleration\n",
    "# excluding the acceleration due to gravity\n",
    "# Triaxial acceleration from the accelerometer is total acceleration\n",
    "SIGNALS = [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ao_ym2YF15zk"
   },
   "outputs": [],
   "source": [
    "# Utility function to read the data from csv file\n",
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "# Utility function to load the load\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'/content/drive/My Drive/Colab Notebooks/HumanActivityRecognition/HAR/UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).to_numpy()\n",
    "        ) \n",
    "\n",
    "    # Transpose is used to change the dimensionality of the output,\n",
    "    # aggregating the signals by combination of sample/timestep.\n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    return np.transpose(signals_data, (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s4mINjp015z9"
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_y(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'/content/drive/My Drive/Colab Notebooks/HumanActivityRecognition/HAR/UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "\n",
    "    #return pd.get_dummies(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UO29ioMH150Q"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train, y_test = load_y('train'), load_y('test')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ssEU5N2o150e"
   },
   "outputs": [],
   "source": [
    "# Importing tensorflow\n",
    "np.random.seed(42)\n",
    "import tensorflow.compat.v1 as tf\n",
    "#tf.disable_v2_behavior()\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jj1QB1Qr150v"
   },
   "outputs": [],
   "source": [
    "# Configuring a session\n",
    "session_conf = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ef0zsPFN151F"
   },
   "outputs": [],
   "source": [
    "# Import Keras\n",
    "from keras import backend as K\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YuyDNG4p151V"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Dropout\n",
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NFuIfUUt151j"
   },
   "outputs": [],
   "source": [
    "# Initializing parameters\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "99Vqhusk151y"
   },
   "outputs": [],
   "source": [
    "# Utility function to count the number of classes\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gNWtO1ul152B"
   },
   "outputs": [],
   "source": [
    "# Loading the train and test data\n",
    "X_train, X_test, Y_train, Y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "N1Q98CVZ152R",
    "outputId": "c9088f4d-203b-42ed-d36a-e65ea7a0ca40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "9\n",
      "7352\n",
      "(7352, 128, 9)\n"
     ]
    }
   ],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "#n_classes = _count_classes(Y_train)\n",
    "\n",
    "print(timesteps)\n",
    "print(input_dim)\n",
    "print(len(X_train))\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "gXwvCh_A_J-K",
    "outputId": "f7bcd9fb-959b-477d-b32f-44e0c5bd6535"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O1Ehdrgd152i"
   },
   "source": [
    "## Defining the Architecture of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N-sUcZto152m",
    "outputId": "75db0ad1-84be-4c1c-c3a8-8170c3ad4817"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 32)                5376      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 5,574\n",
      "Trainable params: 5,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FqTZLfUK1524"
   },
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s8puL7py153G",
    "outputId": "e5bda707-f2f3-4c95-c6a4-73f69918702a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 1.3018 - acc: 0.4395 - val_loss: 1.1254 - val_acc: 0.4662\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.9666 - acc: 0.5880 - val_loss: 0.9491 - val_acc: 0.5714\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 97s 13ms/step - loss: 0.7812 - acc: 0.6408 - val_loss: 0.8286 - val_acc: 0.5850\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 95s 13ms/step - loss: 0.6941 - acc: 0.6574 - val_loss: 0.7297 - val_acc: 0.6128\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 0.6336 - acc: 0.6912 - val_loss: 0.7359 - val_acc: 0.6787\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.5859 - acc: 0.7134 - val_loss: 0.7015 - val_acc: 0.6939\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 95s 13ms/step - loss: 0.5692 - acc: 0.7477 - val_loss: 0.5995 - val_acc: 0.7387\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.4899 - acc: 0.7809 - val_loss: 0.5762 - val_acc: 0.7387\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 90s 12ms/step - loss: 0.4482 - acc: 0.7886 - val_loss: 0.7413 - val_acc: 0.7126\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 90s 12ms/step - loss: 0.4132 - acc: 0.8077 - val_loss: 0.5048 - val_acc: 0.7513\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.3985 - acc: 0.8274 - val_loss: 0.5234 - val_acc: 0.7452\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 91s 12ms/step - loss: 0.3378 - acc: 0.8638 - val_loss: 0.4114 - val_acc: 0.8833\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 91s 12ms/step - loss: 0.2947 - acc: 0.9051 - val_loss: 0.4386 - val_acc: 0.8731\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 90s 12ms/step - loss: 0.2448 - acc: 0.9291 - val_loss: 0.3768 - val_acc: 0.8921\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 91s 12ms/step - loss: 0.2157 - acc: 0.9331 - val_loss: 0.4441 - val_acc: 0.8931\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 90s 12ms/step - loss: 0.2053 - acc: 0.9366 - val_loss: 0.4162 - val_acc: 0.8968\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.2028 - acc: 0.9404 - val_loss: 0.4538 - val_acc: 0.8962\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 93s 13ms/step - loss: 0.1911 - acc: 0.9419 - val_loss: 0.3964 - val_acc: 0.8999\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.1912 - acc: 0.9407 - val_loss: 0.3165 - val_acc: 0.9030\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.1732 - acc: 0.9446 - val_loss: 0.4546 - val_acc: 0.8904\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1782 - acc: 0.9444 - val_loss: 0.3346 - val_acc: 0.9063\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 95s 13ms/step - loss: 0.1812 - acc: 0.9418 - val_loss: 0.8164 - val_acc: 0.8582\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 95s 13ms/step - loss: 0.1824 - acc: 0.9426 - val_loss: 0.4240 - val_acc: 0.9036\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1726 - acc: 0.9429 - val_loss: 0.4067 - val_acc: 0.9148\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.1737 - acc: 0.9411 - val_loss: 0.3396 - val_acc: 0.9074\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.1650 - acc: 0.9461 - val_loss: 0.3806 - val_acc: 0.9019\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.1925 - acc: 0.9415 - val_loss: 0.6464 - val_acc: 0.8850\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 91s 12ms/step - loss: 0.1965 - acc: 0.9425 - val_loss: 0.3363 - val_acc: 0.9203\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 92s 12ms/step - loss: 0.1889 - acc: 0.9431 - val_loss: 0.3737 - val_acc: 0.9158\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 95s 13ms/step - loss: 0.1945 - acc: 0.9414 - val_loss: 0.3088 - val_acc: 0.9097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29b5ee36a20>"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y-5Z2RKU153a",
    "outputId": "0cccf36c-5e42-49ab-f957-7846050a762a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 512        0        25        0                   0   \n",
      "SITTING                  3      410        75        0                   0   \n",
      "STANDING                 0       87       445        0                   0   \n",
      "WALKING                  0        0         0      481                   2   \n",
      "WALKING_DOWNSTAIRS       0        0         0        0                 382   \n",
      "WALKING_UPSTAIRS         0        0         0        2                  18   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            3  \n",
      "STANDING                           0  \n",
      "WALKING                           13  \n",
      "WALKING_DOWNSTAIRS                38  \n",
      "WALKING_UPSTAIRS                 451  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KTN12jVi153r",
    "outputId": "eddb5a28-0ad3-43b7-ab79-aeb7bc0d9031"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 4s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qr_oQShg153_",
    "outputId": "de5067b1-43ba-4e5c-9c0e-9f9dc79135e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3087582236972612, 0.9097387173396675]"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P1asK1SJ154P"
   },
   "source": [
    "- With a simple 2 layer architecture we got 90.09% accuracy and a loss of 0.30\n",
    "- We can further imporve the performace with Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c-oR6VnPjKJb"
   },
   "source": [
    "## LSTM layer with hidden units 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XaKfC-sIIK-m"
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "cP5L-qG-_FG0",
    "outputId": "d06fd0bf-b704-4e15-daaa-e7cf924ce6d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 50)                12000     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 12,306\n",
      "Trainable params: 12,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lKSmWGLbIdvI"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "UB3jlm3jKp-O",
    "outputId": "1b83e584-0899-4ab2-fee8-400ff14b0030"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 1.2245 - accuracy: 0.4805 - val_loss: 0.9273 - val_accuracy: 0.6291\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.7986 - accuracy: 0.6435 - val_loss: 0.7593 - val_accuracy: 0.6322\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.7042 - accuracy: 0.6668 - val_loss: 0.7221 - val_accuracy: 0.6491\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.5705 - accuracy: 0.7715 - val_loss: 0.6119 - val_accuracy: 0.7933\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.4533 - accuracy: 0.8498 - val_loss: 0.4484 - val_accuracy: 0.8459\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.3434 - accuracy: 0.8980 - val_loss: 0.5086 - val_accuracy: 0.8402\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.2782 - accuracy: 0.9109 - val_loss: 0.5094 - val_accuracy: 0.8232\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.2376 - accuracy: 0.9223 - val_loss: 0.3673 - val_accuracy: 0.8670\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.2113 - accuracy: 0.9283 - val_loss: 0.4149 - val_accuracy: 0.8877\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.2115 - accuracy: 0.9298 - val_loss: 0.3622 - val_accuracy: 0.8918\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1846 - accuracy: 0.9365 - val_loss: 0.3946 - val_accuracy: 0.8856\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1844 - accuracy: 0.9359 - val_loss: 0.5115 - val_accuracy: 0.8476\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1845 - accuracy: 0.9382 - val_loss: 0.3616 - val_accuracy: 0.8968\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1796 - accuracy: 0.9391 - val_loss: 0.3955 - val_accuracy: 0.8924\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1777 - accuracy: 0.9406 - val_loss: 0.4987 - val_accuracy: 0.8785\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1797 - accuracy: 0.9416 - val_loss: 0.3987 - val_accuracy: 0.8901\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1568 - accuracy: 0.9449 - val_loss: 0.3686 - val_accuracy: 0.8904\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1953 - accuracy: 0.9346 - val_loss: 0.3931 - val_accuracy: 0.8863\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1547 - accuracy: 0.9459 - val_loss: 0.6165 - val_accuracy: 0.8877\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.2749 - accuracy: 0.9131 - val_loss: 0.3050 - val_accuracy: 0.9094\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1711 - accuracy: 0.9445 - val_loss: 0.3854 - val_accuracy: 0.8948\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1720 - accuracy: 0.9431 - val_loss: 0.3018 - val_accuracy: 0.9026\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1457 - accuracy: 0.9460 - val_loss: 0.3278 - val_accuracy: 0.9114\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.2021 - accuracy: 0.9400 - val_loss: 0.3906 - val_accuracy: 0.9084\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1436 - accuracy: 0.9471 - val_loss: 0.2961 - val_accuracy: 0.9101\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1445 - accuracy: 0.9484 - val_loss: 0.2847 - val_accuracy: 0.9175\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1467 - accuracy: 0.9490 - val_loss: 0.4584 - val_accuracy: 0.9067\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1374 - accuracy: 0.9505 - val_loss: 0.4021 - val_accuracy: 0.8968\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1402 - accuracy: 0.9478 - val_loss: 0.3758 - val_accuracy: 0.9101\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1430 - accuracy: 0.9504 - val_loss: 0.4077 - val_accuracy: 0.9114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe5aa9e4668>"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pQ86-MmDjVN8"
   },
   "source": [
    "## LSTM layer with hidden units 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CAbKnBo4KuP6"
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "ZKka1lcLPPF5",
    "outputId": "a1f6fda6-cf8f-44db-af88-9a4fe2a748cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 100)               44000     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 44,606\n",
      "Trainable params: 44,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g25jvfYjPTUn"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ZxjMI-HgPXLy",
    "outputId": "92cc9514-42fc-4c95-b928-a7292912e33c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 43s 6ms/step - loss: 1.2099 - accuracy: 0.4747 - val_loss: 1.1969 - val_accuracy: 0.4880\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.8234 - accuracy: 0.6240 - val_loss: 0.8039 - val_accuracy: 0.6373\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.6561 - accuracy: 0.7212 - val_loss: 0.7731 - val_accuracy: 0.7431\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.4594 - accuracy: 0.8358 - val_loss: 0.5050 - val_accuracy: 0.8575\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.3005 - accuracy: 0.9014 - val_loss: 0.4458 - val_accuracy: 0.8700\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.2409 - accuracy: 0.9187 - val_loss: 0.9047 - val_accuracy: 0.8144\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 0.2143 - accuracy: 0.9293 - val_loss: 0.6157 - val_accuracy: 0.8534\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.1985 - accuracy: 0.9338 - val_loss: 0.3297 - val_accuracy: 0.9002\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.1906 - accuracy: 0.9319 - val_loss: 0.3126 - val_accuracy: 0.8958\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.1807 - accuracy: 0.9362 - val_loss: 0.3122 - val_accuracy: 0.8890\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.1603 - accuracy: 0.9440 - val_loss: 0.3206 - val_accuracy: 0.9158\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.1674 - accuracy: 0.9427 - val_loss: 0.5436 - val_accuracy: 0.8887\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.1646 - accuracy: 0.9445 - val_loss: 0.3565 - val_accuracy: 0.8836\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 0.1606 - accuracy: 0.9415 - val_loss: 0.3595 - val_accuracy: 0.9080\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 0.1471 - accuracy: 0.9474 - val_loss: 0.2843 - val_accuracy: 0.9033\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.1425 - accuracy: 0.9459 - val_loss: 0.3399 - val_accuracy: 0.9077\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.1533 - accuracy: 0.9475 - val_loss: 0.3868 - val_accuracy: 0.8968\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.1371 - accuracy: 0.9509 - val_loss: 0.4026 - val_accuracy: 0.9050\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.1476 - accuracy: 0.9472 - val_loss: 0.2758 - val_accuracy: 0.9155\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.1336 - accuracy: 0.9508 - val_loss: 0.5425 - val_accuracy: 0.8931\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 0.1632 - accuracy: 0.9427 - val_loss: 0.2898 - val_accuracy: 0.9097\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.1360 - accuracy: 0.9498 - val_loss: 0.4142 - val_accuracy: 0.9125\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.1351 - accuracy: 0.9506 - val_loss: 0.2514 - val_accuracy: 0.9175\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.1338 - accuracy: 0.9514 - val_loss: 0.4072 - val_accuracy: 0.9087\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.1238 - accuracy: 0.9501 - val_loss: 0.4091 - val_accuracy: 0.9264\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.1351 - accuracy: 0.9518 - val_loss: 0.2663 - val_accuracy: 0.9247\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.1271 - accuracy: 0.9510 - val_loss: 0.3760 - val_accuracy: 0.9152\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 0.1314 - accuracy: 0.9510 - val_loss: 0.3641 - val_accuracy: 0.9165\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.1236 - accuracy: 0.9506 - val_loss: 0.4345 - val_accuracy: 0.9165\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.1282 - accuracy: 0.9498 - val_loss: 0.4337 - val_accuracy: 0.9097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe6519ae470>"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ToRuS6IIpSUW"
   },
   "source": [
    "## LSTM layer with hidden units 50 and Stacked 2 LSTM layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DPdqrsGTVxDi"
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "fy14wiO-PZH3",
    "outputId": "27b659d7-90a4-459b-e31a-6d6d1880c4dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 128, 50)           12000     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 32,506\n",
      "Trainable params: 32,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim),return_sequences=True))\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kQMBZL-VV1fW"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ZqCH-LL1V5Ba",
    "outputId": "a975229d-a476-483d-d47f-1559e7002808"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 1.0297 - accuracy: 0.5866 - val_loss: 1.0364 - val_accuracy: 0.5786\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.6456 - accuracy: 0.7368 - val_loss: 0.5441 - val_accuracy: 0.7659\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.5060 - accuracy: 0.8007 - val_loss: 0.5274 - val_accuracy: 0.7947\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.3760 - accuracy: 0.8837 - val_loss: 0.3860 - val_accuracy: 0.8799\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.2305 - accuracy: 0.9261 - val_loss: 0.5078 - val_accuracy: 0.8619\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1899 - accuracy: 0.9397 - val_loss: 0.5318 - val_accuracy: 0.8853\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1733 - accuracy: 0.9423 - val_loss: 0.5450 - val_accuracy: 0.8714\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1638 - accuracy: 0.9442 - val_loss: 0.3468 - val_accuracy: 0.9175\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1603 - accuracy: 0.9445 - val_loss: 0.5124 - val_accuracy: 0.8955\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1512 - accuracy: 0.9480 - val_loss: 0.4302 - val_accuracy: 0.9087\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1577 - accuracy: 0.9487 - val_loss: 0.4821 - val_accuracy: 0.9009\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1399 - accuracy: 0.9494 - val_loss: 0.4780 - val_accuracy: 0.9118\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1467 - accuracy: 0.9476 - val_loss: 0.5243 - val_accuracy: 0.9118\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1439 - accuracy: 0.9502 - val_loss: 0.4510 - val_accuracy: 0.9155\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1393 - accuracy: 0.9484 - val_loss: 0.4472 - val_accuracy: 0.9114\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1423 - accuracy: 0.9535 - val_loss: 0.5377 - val_accuracy: 0.9067\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1413 - accuracy: 0.9470 - val_loss: 0.4461 - val_accuracy: 0.9243\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1333 - accuracy: 0.9495 - val_loss: 0.5249 - val_accuracy: 0.9162\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1227 - accuracy: 0.9512 - val_loss: 0.7599 - val_accuracy: 0.8721\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1269 - accuracy: 0.9505 - val_loss: 0.3871 - val_accuracy: 0.9230\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1319 - accuracy: 0.9505 - val_loss: 0.4414 - val_accuracy: 0.8955\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1276 - accuracy: 0.9523 - val_loss: 0.4278 - val_accuracy: 0.9114\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1239 - accuracy: 0.9520 - val_loss: 0.4113 - val_accuracy: 0.9108\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1269 - accuracy: 0.9540 - val_loss: 0.7708 - val_accuracy: 0.8819\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1427 - accuracy: 0.9512 - val_loss: 0.5201 - val_accuracy: 0.9063\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1236 - accuracy: 0.9518 - val_loss: 0.6123 - val_accuracy: 0.9063\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1253 - accuracy: 0.9539 - val_loss: 0.5630 - val_accuracy: 0.9084\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1251 - accuracy: 0.9529 - val_loss: 0.6175 - val_accuracy: 0.9050\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1183 - accuracy: 0.9570 - val_loss: 0.6973 - val_accuracy: 0.8996\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1325 - accuracy: 0.9532 - val_loss: 0.4317 - val_accuracy: 0.9152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe5a985d080>"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Hl3tJl5pyoq"
   },
   "source": [
    "## LSTM layer with hidden units 100 and Stacked 2 LSTM layer with Dropout 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M2IvVR2GV7eK"
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "pmfCTycEnbXf",
    "outputId": "74da7d76-dbae-4888-d152-6b3516f9625a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 128, 100)          44000     \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 125,006\n",
      "Trainable params: 125,006\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim),return_sequences=True,))\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.7))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UqnihmGVstdg"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Xiv4oJYisyKT",
    "outputId": "0a71e79b-ad67-45e6-a7cf-bad40f0e757a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 87s 12ms/step - loss: 1.0227 - accuracy: 0.5442 - val_loss: 1.3878 - val_accuracy: 0.4710\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 87s 12ms/step - loss: 0.7390 - accuracy: 0.6786 - val_loss: 0.7332 - val_accuracy: 0.7106\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 90s 12ms/step - loss: 0.5430 - accuracy: 0.7961 - val_loss: 0.4565 - val_accuracy: 0.8592\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 90s 12ms/step - loss: 0.3026 - accuracy: 0.9083 - val_loss: 0.4813 - val_accuracy: 0.8772\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 90s 12ms/step - loss: 0.2307 - accuracy: 0.9212 - val_loss: 0.3086 - val_accuracy: 0.9108\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 90s 12ms/step - loss: 0.1905 - accuracy: 0.9363 - val_loss: 0.8151 - val_accuracy: 0.8459\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 90s 12ms/step - loss: 0.3205 - accuracy: 0.8917 - val_loss: 0.4231 - val_accuracy: 0.8965\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 92s 12ms/step - loss: 0.1774 - accuracy: 0.9408 - val_loss: 0.4497 - val_accuracy: 0.8911\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 90s 12ms/step - loss: 0.1517 - accuracy: 0.9470 - val_loss: 0.4013 - val_accuracy: 0.9169\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 90s 12ms/step - loss: 0.1614 - accuracy: 0.9482 - val_loss: 0.4548 - val_accuracy: 0.9125\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 91s 12ms/step - loss: 0.1704 - accuracy: 0.9448 - val_loss: 0.3814 - val_accuracy: 0.9162\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 91s 12ms/step - loss: 0.1413 - accuracy: 0.9476 - val_loss: 0.4954 - val_accuracy: 0.9087\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 93s 13ms/step - loss: 0.1461 - accuracy: 0.9474 - val_loss: 0.5313 - val_accuracy: 0.9074\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 91s 12ms/step - loss: 0.1467 - accuracy: 0.9479 - val_loss: 0.3885 - val_accuracy: 0.9148\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 92s 12ms/step - loss: 0.1476 - accuracy: 0.9475 - val_loss: 0.4466 - val_accuracy: 0.9080\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 90s 12ms/step - loss: 0.1486 - accuracy: 0.9518 - val_loss: 0.4658 - val_accuracy: 0.9141\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 91s 12ms/step - loss: 0.1406 - accuracy: 0.9505 - val_loss: 0.6263 - val_accuracy: 0.8938\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 92s 12ms/step - loss: 0.1393 - accuracy: 0.9524 - val_loss: 0.5257 - val_accuracy: 0.9019\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 91s 12ms/step - loss: 0.1444 - accuracy: 0.9489 - val_loss: 0.5855 - val_accuracy: 0.9077\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 91s 12ms/step - loss: 0.1585 - accuracy: 0.9480 - val_loss: 0.6387 - val_accuracy: 0.8962\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 91s 12ms/step - loss: 0.1455 - accuracy: 0.9479 - val_loss: 0.5438 - val_accuracy: 0.9141\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 91s 12ms/step - loss: 0.1363 - accuracy: 0.9499 - val_loss: 0.5109 - val_accuracy: 0.9108\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 91s 12ms/step - loss: 0.1387 - accuracy: 0.9523 - val_loss: 0.6305 - val_accuracy: 0.9114\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 90s 12ms/step - loss: 0.1345 - accuracy: 0.9509 - val_loss: 0.6063 - val_accuracy: 0.9080\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 91s 12ms/step - loss: 0.1440 - accuracy: 0.9483 - val_loss: 0.7791 - val_accuracy: 0.8965\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 90s 12ms/step - loss: 0.1306 - accuracy: 0.9514 - val_loss: 0.4863 - val_accuracy: 0.9135\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 90s 12ms/step - loss: 0.1374 - accuracy: 0.9476 - val_loss: 0.8820 - val_accuracy: 0.8890\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 91s 12ms/step - loss: 0.1315 - accuracy: 0.9544 - val_loss: 0.4914 - val_accuracy: 0.9257\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 91s 12ms/step - loss: 0.1275 - accuracy: 0.9542 - val_loss: 0.5939 - val_accuracy: 0.9172\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 91s 12ms/step - loss: 0.1362 - accuracy: 0.9516 - val_loss: 0.5559 - val_accuracy: 0.9206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe5a9422860>"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YaHUeLqhqGq_"
   },
   "source": [
    "## LSTM layer with hidden units 200 and Stacked 2 LSTM Layer with Dropout 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "koeNuJn7s3sS"
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "85HmnrfZImaE",
    "outputId": "65d0a332-e8f2-496c-a085-b81edd719b52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_13 (LSTM)               (None, 128, 200)          168000    \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 1206      \n",
      "=================================================================\n",
      "Total params: 490,006\n",
      "Trainable params: 490,006\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim),return_sequences=True))\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.7))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rrvokN-8ItjU"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "X2xLhWcOI7yB",
    "outputId": "810fab42-60ca-42eb-9982-51e359624755"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 201s 27ms/step - loss: 1.2386 - accuracy: 0.4478 - val_loss: 1.2469 - val_accuracy: 0.4601\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 198s 27ms/step - loss: 1.1362 - accuracy: 0.4927 - val_loss: 1.0139 - val_accuracy: 0.5300\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 199s 27ms/step - loss: 1.1668 - accuracy: 0.4853 - val_loss: 0.8508 - val_accuracy: 0.6016\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 198s 27ms/step - loss: 0.7243 - accuracy: 0.6404 - val_loss: 0.7373 - val_accuracy: 0.6077\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 199s 27ms/step - loss: 0.6769 - accuracy: 0.6869 - val_loss: 1.3507 - val_accuracy: 0.5921\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 199s 27ms/step - loss: 0.4137 - accuracy: 0.8570 - val_loss: 0.4040 - val_accuracy: 0.8565\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 199s 27ms/step - loss: 0.2582 - accuracy: 0.9087 - val_loss: 0.5350 - val_accuracy: 0.8449\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 199s 27ms/step - loss: 0.1973 - accuracy: 0.9276 - val_loss: 0.5600 - val_accuracy: 0.8687\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 199s 27ms/step - loss: 0.2003 - accuracy: 0.9297 - val_loss: 0.4190 - val_accuracy: 0.8799\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 199s 27ms/step - loss: 0.1715 - accuracy: 0.9403 - val_loss: 0.3767 - val_accuracy: 0.8958\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 200s 27ms/step - loss: 0.1737 - accuracy: 0.9410 - val_loss: 0.4010 - val_accuracy: 0.9162\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 199s 27ms/step - loss: 0.1726 - accuracy: 0.9434 - val_loss: 0.4281 - val_accuracy: 0.8985\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 200s 27ms/step - loss: 0.1631 - accuracy: 0.9425 - val_loss: 0.5152 - val_accuracy: 0.9165\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 201s 27ms/step - loss: 0.1471 - accuracy: 0.9470 - val_loss: 0.4265 - val_accuracy: 0.8996\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 199s 27ms/step - loss: 0.1678 - accuracy: 0.9429 - val_loss: 0.4384 - val_accuracy: 0.9070\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 200s 27ms/step - loss: 0.1545 - accuracy: 0.9479 - val_loss: 0.4240 - val_accuracy: 0.9111\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 198s 27ms/step - loss: 0.1451 - accuracy: 0.9472 - val_loss: 0.2985 - val_accuracy: 0.9233\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 199s 27ms/step - loss: 0.1478 - accuracy: 0.9436 - val_loss: 0.4533 - val_accuracy: 0.9043\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 201s 27ms/step - loss: 0.1408 - accuracy: 0.9514 - val_loss: 0.7595 - val_accuracy: 0.8833\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 198s 27ms/step - loss: 0.1510 - accuracy: 0.9502 - val_loss: 0.4704 - val_accuracy: 0.9179\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 199s 27ms/step - loss: 0.1494 - accuracy: 0.9449 - val_loss: 0.4327 - val_accuracy: 0.9141\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 199s 27ms/step - loss: 0.1526 - accuracy: 0.9464 - val_loss: 0.5509 - val_accuracy: 0.8948\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 198s 27ms/step - loss: 0.1298 - accuracy: 0.9508 - val_loss: 0.3157 - val_accuracy: 0.9206\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 199s 27ms/step - loss: 0.1456 - accuracy: 0.9475 - val_loss: 0.5093 - val_accuracy: 0.9111\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 199s 27ms/step - loss: 0.1502 - accuracy: 0.9489 - val_loss: 0.4300 - val_accuracy: 0.9182\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 199s 27ms/step - loss: 0.1636 - accuracy: 0.9486 - val_loss: 0.4425 - val_accuracy: 0.9094\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 199s 27ms/step - loss: 0.1596 - accuracy: 0.9497 - val_loss: 0.4461 - val_accuracy: 0.9233\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 200s 27ms/step - loss: 0.1849 - accuracy: 0.9392 - val_loss: 0.5518 - val_accuracy: 0.9128\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 200s 27ms/step - loss: 0.1469 - accuracy: 0.9491 - val_loss: 0.4572 - val_accuracy: 0.9111\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 200s 27ms/step - loss: 0.1663 - accuracy: 0.9461 - val_loss: 0.4729 - val_accuracy: 0.9135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe5a86cf128>"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),a\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7sm3u97WonWf"
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 50\n",
    "n_hidden = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "vMnpEHVIFxSP",
    "outputId": "81f7b77c-1cec-4866-f507-569b7b8680d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_18 (LSTM)               (None, 128, 400)          656000    \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 400)               1281600   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 6)                 2406      \n",
      "=================================================================\n",
      "Total params: 1,940,006\n",
      "Trainable params: 1,940,006\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim),return_sequences=True))\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yE_7K1SlLXA-"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-9kRZZAGLbyK",
    "outputId": "74719021-d030-4aa6-f865-d247cd06ba42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 376s 51ms/step - loss: 1.3895 - accuracy: 0.3630 - val_loss: 1.4433 - val_accuracy: 0.3448\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 371s 50ms/step - loss: 1.5051 - accuracy: 0.3419 - val_loss: 1.3643 - val_accuracy: 0.3536\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 367s 50ms/step - loss: 1.6174 - accuracy: 0.2947 - val_loss: 2.2827 - val_accuracy: 0.1805\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 372s 51ms/step - loss: 1.3847 - accuracy: 0.3663 - val_loss: 1.2864 - val_accuracy: 0.3885\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 377s 51ms/step - loss: 1.3023 - accuracy: 0.4094 - val_loss: 1.4268 - val_accuracy: 0.3427\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 376s 51ms/step - loss: 1.5229 - accuracy: 0.3307 - val_loss: 1.3071 - val_accuracy: 0.4007\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 365s 50ms/step - loss: 1.2189 - accuracy: 0.4412 - val_loss: 1.0330 - val_accuracy: 0.4734\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 369s 50ms/step - loss: 1.2096 - accuracy: 0.4498 - val_loss: 1.2878 - val_accuracy: 0.4075\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 369s 50ms/step - loss: 1.2264 - accuracy: 0.4433 - val_loss: 1.2485 - val_accuracy: 0.4540\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 365s 50ms/step - loss: 1.0674 - accuracy: 0.5260 - val_loss: 1.0025 - val_accuracy: 0.5976\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 371s 50ms/step - loss: 0.7309 - accuracy: 0.6468 - val_loss: 0.8430 - val_accuracy: 0.6291\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 367s 50ms/step - loss: 0.5931 - accuracy: 0.7397 - val_loss: 0.4590 - val_accuracy: 0.8219\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 370s 50ms/step - loss: 0.3360 - accuracy: 0.8787 - val_loss: 0.3739 - val_accuracy: 0.8707\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 372s 51ms/step - loss: 0.2674 - accuracy: 0.9063 - val_loss: 0.3638 - val_accuracy: 0.8839\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 369s 50ms/step - loss: 0.2039 - accuracy: 0.9251 - val_loss: 0.2553 - val_accuracy: 0.8985\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 370s 50ms/step - loss: 0.2205 - accuracy: 0.9204 - val_loss: 0.6894 - val_accuracy: 0.7285\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 368s 50ms/step - loss: 0.2318 - accuracy: 0.9052 - val_loss: 0.3073 - val_accuracy: 0.9040\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 374s 51ms/step - loss: 0.1496 - accuracy: 0.9425 - val_loss: 0.4131 - val_accuracy: 0.8901\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 371s 50ms/step - loss: 0.1757 - accuracy: 0.9396 - val_loss: 0.2300 - val_accuracy: 0.9094\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 367s 50ms/step - loss: 0.1451 - accuracy: 0.9395 - val_loss: 0.3788 - val_accuracy: 0.8958\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 371s 50ms/step - loss: 0.1399 - accuracy: 0.9452 - val_loss: 0.3568 - val_accuracy: 0.9091\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 372s 51ms/step - loss: 0.1249 - accuracy: 0.9510 - val_loss: 0.2756 - val_accuracy: 0.9148\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 372s 51ms/step - loss: 0.1366 - accuracy: 0.9514 - val_loss: 0.4882 - val_accuracy: 0.8958\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 372s 51ms/step - loss: 0.1244 - accuracy: 0.9502 - val_loss: 0.4677 - val_accuracy: 0.8962\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 368s 50ms/step - loss: 0.1301 - accuracy: 0.9518 - val_loss: 0.3033 - val_accuracy: 0.9243\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 372s 51ms/step - loss: 0.1247 - accuracy: 0.9479 - val_loss: 0.2570 - val_accuracy: 0.9199\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 368s 50ms/step - loss: 0.1289 - accuracy: 0.9524 - val_loss: 0.2672 - val_accuracy: 0.9158\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 373s 51ms/step - loss: 0.1139 - accuracy: 0.9524 - val_loss: 0.2991 - val_accuracy: 0.9247\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 372s 51ms/step - loss: 0.1339 - accuracy: 0.9517 - val_loss: 0.2612 - val_accuracy: 0.9203\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 367s 50ms/step - loss: 0.1228 - accuracy: 0.9487 - val_loss: 0.4365 - val_accuracy: 0.9033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fc90515c7b8>"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lqnQwiJYAN8P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f9XRK0_R4StP"
   },
   "source": [
    "# DIVIDE MY CONQUER USING CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8kwQh8q_BtS6",
    "outputId": "50a2ef59-bcd9-40ef-a552-9c0bc6fe8595"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Inertial Signals'   subject_train.txt\t X_train.txt   y_train.txt\n"
     ]
    }
   ],
   "source": [
    "!ls \"drive/My Drive/Colab Notebooks/HumanActivityRecognition/HAR/UCI_HAR_Dataset/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nDr0HAKfLLo_",
    "outputId": "a1fff371-2d01-43a5-ff18-d02f697c6989"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,CuDNNLSTM,BatchNormalization\n",
    "from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
    "from keras.layers.embeddings import Embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A9BgXM7I4Js6"
   },
   "source": [
    "##Loading the Output labels by spliting into Static and Dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lApfSm6DBtyp"
   },
   "outputs": [],
   "source": [
    "#code is taken from this website and modified according to my requirement github.com/xSachinBharadwajx/Human-Activity-Recognition-Using-Smartphones-DivideAndConquer/blob/master/ConquerDivide_HAR.ipynb\n",
    "def load_op_2(incoming1,incoming2):\n",
    "  \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "  #path=\"drive/My Drive/Data/Human_activity_recognition\" +'/'+ incoming +'.txt'\n",
    "  path=\"drive/My Drive/Colab Notebooks/HumanActivityRecognition/HAR/UCI_HAR_Dataset/\"+incoming2+'/'+incoming1+'.txt'\n",
    "  df=pd.read_csv(path, delim_whitespace=True, header=None)[0]\n",
    "  df[df<=3] = 0\n",
    "  df[df>3] = 1\n",
    "  return pd.get_dummies(df).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "utnv83O93rwu",
    "outputId": "adb14fd0-b5ff-4181-9259-00ed5ddcdec9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 2)\n",
      "(2947, 2)\n"
     ]
    }
   ],
   "source": [
    "y_train_2=load_op_2('y_train',\"train\")\n",
    "y_test_2=load_op_2('y_test',\"test\")\n",
    "print(y_train_2.shape)\n",
    "print(y_test_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZpNpcMMz4lvl"
   },
   "source": [
    "##Model for classifying data into Static and Dynamic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "7HA-rK0hKTSH",
    "outputId": "ee161c7f-054a-4e69-c733-60f83003aa0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/10\n",
      "7352/7352 [==============================] - 6s 760us/step - loss: 0.0345 - accuracy: 0.9868 - val_loss: 0.0338 - val_accuracy: 0.9783\n",
      "Epoch 2/10\n",
      "7352/7352 [==============================] - 5s 727us/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.0117 - val_accuracy: 0.9963\n",
      "Epoch 3/10\n",
      "7352/7352 [==============================] - 6s 755us/step - loss: 8.8948e-04 - accuracy: 0.9996 - val_loss: 0.0077 - val_accuracy: 0.9983\n",
      "Epoch 4/10\n",
      "7352/7352 [==============================] - 5s 710us/step - loss: 6.0257e-05 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 0.9983\n",
      "Epoch 5/10\n",
      "7352/7352 [==============================] - 5s 666us/step - loss: 2.3451e-05 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9983\n",
      "Epoch 6/10\n",
      "7352/7352 [==============================] - 5s 658us/step - loss: 1.0934e-05 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9983\n",
      "Epoch 7/10\n",
      "7352/7352 [==============================] - 5s 645us/step - loss: 1.0018e-05 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9983\n",
      "Epoch 8/10\n",
      "7352/7352 [==============================] - 5s 659us/step - loss: 5.0086e-06 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9980\n",
      "Epoch 9/10\n",
      "7352/7352 [==============================] - 5s 687us/step - loss: 3.4142e-06 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 0.9980\n",
      "Epoch 10/10\n",
      "7352/7352 [==============================] - 5s 665us/step - loss: 3.9038e-06 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 0.9980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f6027e50940>"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu',kernel_initializer='he_uniform',input_shape=(128,9)))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu',kernel_initializer='he_uniform'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train,y_train_2, epochs=10, batch_size=16,validation_data=(X_test, y_test_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8LbWqhuR4rRB"
   },
   "source": [
    "##Save the 2 class classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DugT3BI3LWb0"
   },
   "outputs": [],
   "source": [
    "model.save('drive/My Drive/Colab Notebooks/HumanActivityRecognition/model_2class.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hK_z8-FU40So"
   },
   "source": [
    "##Classificaton of Static activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cuTJNoCaNvUL"
   },
   "outputs": [],
   "source": [
    "def load_op_stat(incoming1,incoming2):\n",
    "  \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "  path=\"drive/My Drive/Colab Notebooks/HumanActivityRecognition/HAR/UCI_HAR_Dataset/\"+incoming2+'/'+incoming1+'.txt'\n",
    "  \n",
    "  df=pd.read_csv(path, delim_whitespace=True, header=None)[0]\n",
    "  df_subset=df>3\n",
    "  df=df[df_subset]\n",
    "  return pd.get_dummies(df).to_numpy(),df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "M1CQV7FuN-M6",
    "outputId": "c2a72e93-d7e3-4adc-928a-dbbf3c569ad7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4067, 3)\n",
      "(1560, 3)\n",
      "(1560, 128, 9)\n",
      "(4067, 128, 9)\n"
     ]
    }
   ],
   "source": [
    "y_train_stat,x_train_size=load_op_stat('y_train','train')\n",
    "y_test_stat,x_test_size=load_op_stat('y_test','test')\n",
    "X_train_stat=X_train[x_train_size]\n",
    "X_test_stat=X_test[x_test_size]\n",
    "print(y_train_stat.shape)\n",
    "print(y_test_stat.shape)\n",
    "print(X_test_stat.shape)\n",
    "print(X_train_stat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4B2tex5Y4-Hf"
   },
   "source": [
    "##Model for Static Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "uVd9yWVUOOB0",
    "outputId": "9e6bec40-5ae7-4bf0-8416-d5ad1ddb5d73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4067 samples, validate on 1560 samples\n",
      "Epoch 1/30\n",
      "4067/4067 [==============================] - 4s 1ms/step - loss: 0.5644 - accuracy: 0.7866 - val_loss: 0.4062 - val_accuracy: 0.8487\n",
      "Epoch 2/30\n",
      "4067/4067 [==============================] - 4s 965us/step - loss: 0.3247 - accuracy: 0.8844 - val_loss: 0.3619 - val_accuracy: 0.8891\n",
      "Epoch 3/30\n",
      "4067/4067 [==============================] - 4s 955us/step - loss: 0.2981 - accuracy: 0.8921 - val_loss: 0.3128 - val_accuracy: 0.8808\n",
      "Epoch 4/30\n",
      "4067/4067 [==============================] - 4s 969us/step - loss: 0.2971 - accuracy: 0.8962 - val_loss: 0.3310 - val_accuracy: 0.8679\n",
      "Epoch 5/30\n",
      "4067/4067 [==============================] - 4s 954us/step - loss: 0.2567 - accuracy: 0.9019 - val_loss: 0.2835 - val_accuracy: 0.8821\n",
      "Epoch 6/30\n",
      "4067/4067 [==============================] - 4s 949us/step - loss: 0.2705 - accuracy: 0.9014 - val_loss: 0.3198 - val_accuracy: 0.8846\n",
      "Epoch 7/30\n",
      "4067/4067 [==============================] - 4s 942us/step - loss: 0.2525 - accuracy: 0.9063 - val_loss: 0.3982 - val_accuracy: 0.8571\n",
      "Epoch 8/30\n",
      "4067/4067 [==============================] - 4s 960us/step - loss: 0.2604 - accuracy: 0.9046 - val_loss: 0.2895 - val_accuracy: 0.8795\n",
      "Epoch 9/30\n",
      "4067/4067 [==============================] - 4s 972us/step - loss: 0.2622 - accuracy: 0.9041 - val_loss: 0.2825 - val_accuracy: 0.9064\n",
      "Epoch 10/30\n",
      "4067/4067 [==============================] - 4s 955us/step - loss: 0.2258 - accuracy: 0.9154 - val_loss: 0.3143 - val_accuracy: 0.8840\n",
      "Epoch 11/30\n",
      "4067/4067 [==============================] - 4s 950us/step - loss: 0.2397 - accuracy: 0.9159 - val_loss: 0.3028 - val_accuracy: 0.8910\n",
      "Epoch 12/30\n",
      "4067/4067 [==============================] - 4s 953us/step - loss: 0.2328 - accuracy: 0.9174 - val_loss: 0.3252 - val_accuracy: 0.8974\n",
      "Epoch 13/30\n",
      "4067/4067 [==============================] - 4s 948us/step - loss: 0.2328 - accuracy: 0.9154 - val_loss: 0.4077 - val_accuracy: 0.8462\n",
      "Epoch 14/30\n",
      "4067/4067 [==============================] - 4s 953us/step - loss: 0.2233 - accuracy: 0.9181 - val_loss: 0.2782 - val_accuracy: 0.8891\n",
      "Epoch 15/30\n",
      "4067/4067 [==============================] - 4s 974us/step - loss: 0.2052 - accuracy: 0.9289 - val_loss: 0.2884 - val_accuracy: 0.8923\n",
      "Epoch 16/30\n",
      "4067/4067 [==============================] - 4s 975us/step - loss: 0.2226 - accuracy: 0.9240 - val_loss: 0.3063 - val_accuracy: 0.8910\n",
      "Epoch 17/30\n",
      "4067/4067 [==============================] - 4s 992us/step - loss: 0.2026 - accuracy: 0.9294 - val_loss: 0.2511 - val_accuracy: 0.9128\n",
      "Epoch 18/30\n",
      "4067/4067 [==============================] - 4s 976us/step - loss: 0.2178 - accuracy: 0.9253 - val_loss: 0.2786 - val_accuracy: 0.8891\n",
      "Epoch 19/30\n",
      "4067/4067 [==============================] - 4s 985us/step - loss: 0.1997 - accuracy: 0.9348 - val_loss: 0.2860 - val_accuracy: 0.9122\n",
      "Epoch 20/30\n",
      "4067/4067 [==============================] - 4s 985us/step - loss: 0.2276 - accuracy: 0.9289 - val_loss: 0.2510 - val_accuracy: 0.8955\n",
      "Epoch 21/30\n",
      "4067/4067 [==============================] - 4s 970us/step - loss: 0.2071 - accuracy: 0.9294 - val_loss: 0.4226 - val_accuracy: 0.8853\n",
      "Epoch 22/30\n",
      "4067/4067 [==============================] - 4s 975us/step - loss: 0.1974 - accuracy: 0.9321 - val_loss: 0.3387 - val_accuracy: 0.8885\n",
      "Epoch 23/30\n",
      "4067/4067 [==============================] - 4s 990us/step - loss: 0.1943 - accuracy: 0.9356 - val_loss: 0.3394 - val_accuracy: 0.8974\n",
      "Epoch 24/30\n",
      "4067/4067 [==============================] - 4s 984us/step - loss: 0.1884 - accuracy: 0.9371 - val_loss: 0.2404 - val_accuracy: 0.9160\n",
      "Epoch 25/30\n",
      "4067/4067 [==============================] - 4s 996us/step - loss: 0.1917 - accuracy: 0.9395 - val_loss: 0.2648 - val_accuracy: 0.9122\n",
      "Epoch 26/30\n",
      "4067/4067 [==============================] - 4s 959us/step - loss: 0.1804 - accuracy: 0.9442 - val_loss: 0.2633 - val_accuracy: 0.9173\n",
      "Epoch 27/30\n",
      "4067/4067 [==============================] - 4s 967us/step - loss: 0.1797 - accuracy: 0.9407 - val_loss: 0.2259 - val_accuracy: 0.9083\n",
      "Epoch 28/30\n",
      "4067/4067 [==============================] - 4s 993us/step - loss: 0.1731 - accuracy: 0.9422 - val_loss: 0.2469 - val_accuracy: 0.9045\n",
      "Epoch 29/30\n",
      "4067/4067 [==============================] - 4s 1ms/step - loss: 0.1784 - accuracy: 0.9410 - val_loss: 0.2825 - val_accuracy: 0.9173\n",
      "Epoch 30/30\n",
      "4067/4067 [==============================] - 4s 1ms/step - loss: 0.1912 - accuracy: 0.9415 - val_loss: 0.2692 - val_accuracy: 0.9038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f6026ea3b70>"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  model_stat = Sequential()\n",
    "  model_stat.add(Conv1D(filters=64, kernel_size=5,padding='same', activation='relu',kernel_initializer='he_uniform',input_shape=(128,9)))\n",
    "  model_stat.add(Conv1D(filters=32, kernel_size=3,padding='same', activation='relu',kernel_initializer='he_uniform'))\n",
    "  model_stat.add(Dropout(0.6))\n",
    "  model_stat.add(MaxPooling1D(pool_size=1,strides=1))\n",
    "\n",
    "  model_stat.add(Flatten())\n",
    "  model_stat.add(Dense(64, activation='relu',kernel_initializer='he_uniform'))\n",
    "  model_stat.add(BatchNormalization()) \n",
    "  model_stat.add(Dropout(0.6))\n",
    "\n",
    "  model_stat.add(Dense(32, activation='relu',kernel_initializer='he_uniform'))\n",
    "  model_stat.add(BatchNormalization()) \n",
    "  model_stat.add(Dropout(0.6))\n",
    "\n",
    "  model_stat.add(Dense(3, activation='softmax'))\n",
    "\n",
    "  model_stat.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "  model_stat.fit(X_train_stat,y_train_stat, epochs=30, batch_size=16,validation_data=(X_test_stat, y_test_stat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VDllMOyIOmex"
   },
   "outputs": [],
   "source": [
    "model_stat.save('drive/My Drive/Colab Notebooks/HumanActivityRecognition/model_stat_class.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Xx7LXDm5OtE"
   },
   "source": [
    "##Output For Dynamic Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ku0nprYtP-Hf"
   },
   "outputs": [],
   "source": [
    "def load_op_dyn(incoming1,incoming2):\n",
    "  \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "  path=\"drive/My Drive/Colab Notebooks/HumanActivityRecognition/HAR/UCI_HAR_Dataset/\"+incoming2+'/'+incoming1+'.txt'\n",
    "  \n",
    "  df=pd.read_csv(path, delim_whitespace=True, header=None)[0]\n",
    "  df_subset=df<=3\n",
    "  df=df[df_subset]\n",
    "  return pd.get_dummies(df).to_numpy(),df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "NbFSF1cGRaUu",
    "outputId": "41c8471e-e8a4-424a-e093-9194902b698b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3285, 3)\n",
      "(1387, 3)\n",
      "(1387, 128, 9)\n",
      "(3285, 128, 9)\n"
     ]
    }
   ],
   "source": [
    "y_train_dyn,x_train_size=load_op_dyn('y_train','train')\n",
    "y_test_dyn,x_test_size=load_op_dyn('y_test','test')\n",
    "X_train_dyn=X_train[x_train_size]\n",
    "X_test_dyn=X_test[x_test_size]\n",
    "print(y_train_dyn.shape)\n",
    "print(y_test_dyn.shape)\n",
    "print(X_test_dyn.shape)\n",
    "print(X_train_dyn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I8IDBxh55RF3"
   },
   "source": [
    "##Model for Dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "H6NIrXgdStiC",
    "outputId": "afa70f4b-6f2a-4600-fb2a-85d84e930002"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3285 samples, validate on 1387 samples\n",
      "Epoch 1/40\n",
      "3285/3285 [==============================] - 5s 1ms/step - loss: 1.3193 - accuracy: 0.4712 - val_loss: 1.3942 - val_accuracy: 0.4585\n",
      "Epoch 2/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.5140 - accuracy: 0.8000 - val_loss: 0.4088 - val_accuracy: 0.8407\n",
      "Epoch 3/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.2259 - accuracy: 0.9324 - val_loss: 0.3440 - val_accuracy: 0.8688\n",
      "Epoch 4/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.1333 - accuracy: 0.9635 - val_loss: 0.1645 - val_accuracy: 0.9524\n",
      "Epoch 5/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0988 - accuracy: 0.9735 - val_loss: 0.1798 - val_accuracy: 0.9322\n",
      "Epoch 6/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0783 - accuracy: 0.9763 - val_loss: 0.2188 - val_accuracy: 0.9452\n",
      "Epoch 7/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0957 - accuracy: 0.9744 - val_loss: 0.1650 - val_accuracy: 0.9510\n",
      "Epoch 8/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0540 - accuracy: 0.9851 - val_loss: 0.1341 - val_accuracy: 0.9654\n",
      "Epoch 9/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0765 - accuracy: 0.9790 - val_loss: 0.0822 - val_accuracy: 0.9740\n",
      "Epoch 10/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0542 - accuracy: 0.9842 - val_loss: 0.1320 - val_accuracy: 0.9640\n",
      "Epoch 11/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0741 - accuracy: 0.9781 - val_loss: 0.0918 - val_accuracy: 0.9712\n",
      "Epoch 12/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0689 - accuracy: 0.9851 - val_loss: 0.2469 - val_accuracy: 0.9106\n",
      "Epoch 13/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.1667 - accuracy: 0.9516 - val_loss: 0.0955 - val_accuracy: 0.9733\n",
      "Epoch 14/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0515 - accuracy: 0.9851 - val_loss: 0.0850 - val_accuracy: 0.9784\n",
      "Epoch 15/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0433 - accuracy: 0.9887 - val_loss: 0.0715 - val_accuracy: 0.9784\n",
      "Epoch 16/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0560 - accuracy: 0.9848 - val_loss: 0.1080 - val_accuracy: 0.9647\n",
      "Epoch 17/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0270 - accuracy: 0.9930 - val_loss: 0.1171 - val_accuracy: 0.9733\n",
      "Epoch 18/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0216 - accuracy: 0.9951 - val_loss: 0.1408 - val_accuracy: 0.9661\n",
      "Epoch 19/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0198 - accuracy: 0.9948 - val_loss: 0.0792 - val_accuracy: 0.9820\n",
      "Epoch 20/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0273 - accuracy: 0.9906 - val_loss: 0.1214 - val_accuracy: 0.9704\n",
      "Epoch 21/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0850 - accuracy: 0.9772 - val_loss: 0.1398 - val_accuracy: 0.9690\n",
      "Epoch 22/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0278 - accuracy: 0.9918 - val_loss: 0.0960 - val_accuracy: 0.9769\n",
      "Epoch 23/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0536 - accuracy: 0.9848 - val_loss: 0.0617 - val_accuracy: 0.9849\n",
      "Epoch 24/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0162 - accuracy: 0.9957 - val_loss: 0.0596 - val_accuracy: 0.9856\n",
      "Epoch 25/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0157 - accuracy: 0.9957 - val_loss: 0.0657 - val_accuracy: 0.9827\n",
      "Epoch 26/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0182 - accuracy: 0.9948 - val_loss: 0.1192 - val_accuracy: 0.9748\n",
      "Epoch 27/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0195 - accuracy: 0.9936 - val_loss: 0.0571 - val_accuracy: 0.9863\n",
      "Epoch 28/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0249 - accuracy: 0.9948 - val_loss: 0.0677 - val_accuracy: 0.9849\n",
      "Epoch 29/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0516 - accuracy: 0.9878 - val_loss: 0.1540 - val_accuracy: 0.9704\n",
      "Epoch 30/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0335 - accuracy: 0.9918 - val_loss: 0.1268 - val_accuracy: 0.9762\n",
      "Epoch 31/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0175 - accuracy: 0.9954 - val_loss: 0.1170 - val_accuracy: 0.9791\n",
      "Epoch 32/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0126 - accuracy: 0.9970 - val_loss: 0.1711 - val_accuracy: 0.9654\n",
      "Epoch 33/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0165 - accuracy: 0.9960 - val_loss: 0.1880 - val_accuracy: 0.9640\n",
      "Epoch 34/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 0.1178 - val_accuracy: 0.9805\n",
      "Epoch 35/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1241 - val_accuracy: 0.9805\n",
      "Epoch 36/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0059 - accuracy: 0.9991 - val_loss: 0.2239 - val_accuracy: 0.9668\n",
      "Epoch 37/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0342 - accuracy: 0.9915 - val_loss: 0.1060 - val_accuracy: 0.9704\n",
      "Epoch 38/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0333 - accuracy: 0.9906 - val_loss: 0.1256 - val_accuracy: 0.9798\n",
      "Epoch 39/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0319 - accuracy: 0.9915 - val_loss: 0.1362 - val_accuracy: 0.9755\n",
      "Epoch 40/40\n",
      "3285/3285 [==============================] - 4s 1ms/step - loss: 0.0272 - accuracy: 0.9930 - val_loss: 0.1884 - val_accuracy: 0.9668\n",
      "1387/1387 [==============================] - 0s 216us/step\n"
     ]
    }
   ],
   "source": [
    "  model_dyn = Sequential()\n",
    "  model_dyn.add(Conv1D(filters=64, kernel_size=5,padding='same', activation='relu',kernel_initializer='he_uniform',input_shape=(128,9)))\n",
    "  model_dyn.add(Conv1D(filters=32, kernel_size=5,padding='same', activation='relu',kernel_initializer='he_uniform'))\n",
    "  model_dyn.add(Dropout(0.5))\n",
    "  model_dyn.add(MaxPooling1D(pool_size=1,strides=1))\n",
    "\n",
    "  model_dyn.add(Flatten())\n",
    "  model_dyn.add(Dense(64, activation='relu',kernel_initializer='he_uniform'))\n",
    "  model_dyn.add(BatchNormalization()) \n",
    "  model_dyn.add(Dropout(0.5))\n",
    "\n",
    "  model_dyn.add(Dense(32, activation='relu',kernel_initializer='he_uniform'))\n",
    "  model_dyn.add(BatchNormalization()) \n",
    "  model_dyn.add(Dropout(0.5))\n",
    "\n",
    "  model_dyn.add(Dense(3, activation='softmax'))\n",
    "\n",
    "  model_dyn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "  model_dyn.fit(X_train_dyn,y_train_dyn, epochs=40, batch_size=16,validation_data=(X_test_dyn, y_test_dyn),verbose=1)\n",
    "\n",
    "  #Evaluate the model_dyn \n",
    "  score = model_dyn.evaluate(X_test_dyn, y_test_dyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hlO8n4dKS5Fj"
   },
   "outputs": [],
   "source": [
    "model_dyn.save('drive/My Drive/Colab Notebooks/HumanActivityRecognition/model_dyn_class.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mqe4kW4Z5Vwl"
   },
   "source": [
    "##Final Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VMu0fIPLTq7A"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import pickle\n",
    "model_2class = load_model('drive/My Drive/Colab Notebooks/HumanActivityRecognition/model_2class.h5')\n",
    "model_static = load_model('drive/My Drive/Colab Notebooks/HumanActivityRecognition/model_stat_class.h5')\n",
    "model_dynamic = load_model('drive/My Drive/Colab Notebooks/HumanActivityRecognition/model_dyn_class.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MftX2A2pUp6g"
   },
   "outputs": [],
   "source": [
    "predict_2class = model_2class.predict(X_test)\n",
    "Y_pred_2class =  np.argmax(predict_2class, axis=1)\n",
    "#static data filter\n",
    "X_static = X_test[Y_pred_2class==1]\n",
    "#dynamic data filter\n",
    "X_dynamic = X_test[Y_pred_2class==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tbOHnSVuUsx6"
   },
   "outputs": [],
   "source": [
    "predict_static = model_static.predict(X_static)\n",
    "predict_static = np.argmax(predict_static,axis=1)\n",
    "#predict_static = predict_static + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZJrec6eBVl_9",
    "outputId": "082bb45e-0273-462b-cc11-bb422da9f0d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gwyl6zwWVs9b"
   },
   "outputs": [],
   "source": [
    "predict_static = predict_static + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "x85YZvmCVuhv",
    "outputId": "ccf76978-f4f0-41e5-e85c-b085d3343a13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, ..., 6, 6, 6])"
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_97f0p2_V1Jy"
   },
   "outputs": [],
   "source": [
    "predict_dynamic = model_dynamic.predict(X_dynamic)\n",
    "predict_dynamic = np.argmax(predict_dynamic,axis=1)\n",
    "#predict_dynamic = predict_dynamic + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RWnzIETGbloU",
    "outputId": "c0d515b6-25d3-4a16-8054-c7417a5c3e1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 78,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ds-QsP2gboqP"
   },
   "outputs": [],
   "source": [
    "predict_dynamic = predict_dynamic + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "i5F9BmggbrTr",
    "outputId": "e0ba7dbf-4441-4733-d2a5-2673f1ea19a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5bRnooCjbxvZ"
   },
   "outputs": [],
   "source": [
    "i,j = 0,0 \n",
    "final_pred = []\n",
    "for mask in Y_pred_2class:\n",
    "    if mask == 1:\n",
    "        final_pred.append(predict_static[i])\n",
    "        i = i + 1\n",
    "    else:\n",
    "        final_pred.append(predict_dynamic[j])\n",
    "        j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SxN1fVsFb6aK",
    "outputId": "abc878d7-e6b6-424d-aab5-43c1f9362771"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test data 0.9314557176789956\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy of test data',accuracy_score(Y_test,final_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pTnJO2xjc10H"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "plt.rcParams[\"font.family\"] = 'DejaVu Sans'\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oEYaGK7Z5hfz"
   },
   "source": [
    "##CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AvdmjW3TfBU2"
   },
   "outputs": [],
   "source": [
    "labels=['LAYING', 'SITTING','STANDING','WALKING','WALKING_DOWNSTAIRS','WALKING_UPSTAIRS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "colab_type": "code",
    "id": "pXxFBM7pfjH_",
    "outputId": "65e0005d-26ee-47a6-807d-80c09903e716"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    cm = confusion_matrix(Y_test, final_pred)\n",
    "    #results['confusion_matrix'] = cm\n",
    "  \n",
    "        \n",
    "    # plot confusin matrix\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.grid(b=False)\n",
    "    plot_confusion_matrix(cm, classes=labels, normalize=True, title='Normalized confusion matrix', cmap = plt.cm.Greens)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gDZQMFd8qYmI"
   },
   "source": [
    "## CONCLUSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yoHmrA6lLVla"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XqJUSUvFqavp"
   },
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "IF0boUBfurbE",
    "outputId": "f968dcde-e1b3-46a9-bbaa-2ed5afceb465"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------------------+---------+----------------+---------------+\n",
      "|        Model         | nuumber of units | dropout | train accuracy | test accuracy |\n",
      "+----------------------+------------------+---------+----------------+---------------+\n",
      "|     single LSTM      |        32        |   0.5   |     0.9414     |     0.9097    |\n",
      "|     single LSTM      |        50        |   0.5   |     0.9504     |     0.9114    |\n",
      "|     single LSTM      |       100        |   0.5   |     0.9498     |     0.9097    |\n",
      "| Stacked 2 LSTM layer |        50        |   0.5   |     0.9532     |     0.9152    |\n",
      "| stacked 2 LSTM layer |       100        |   0.7   |     0.9516     |     0.9206    |\n",
      "| Stcked 2 LSTM layer  |       200        |   0.7   |     0.9461     |     0.9135    |\n",
      "+----------------------+------------------+---------+----------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "pt=PrettyTable()\n",
    "pt.field_names=[\"Model\",\"number of units\",\"dropout\",\"train accuracy\",\"test accuracy\"]\n",
    "pt.add_row([\"single LSTM\",\"32\",\"0.5\",\"0.9414\",\"0.9097\"])\n",
    "pt.add_row([\"single LSTM\",\"50\",\"0.5\",\"0.9504\",\"0.9114\"])\n",
    "pt.add_row([\"single LSTM\",\"100\",\"0.5\",\"0.9498\",\"0.9097\"])\n",
    "pt.add_row([\"Stacked 2 LSTM layer\",\"50\",\"0.5\",\"0.9532\",\"0.9152\"])\n",
    "pt.add_row([\"stacked 2 LSTM layer\",\"100\",\"0.7\",\"0.9516\",\"0.9206\"])\n",
    "pt.add_row([\"Stcked 2 LSTM layer\",\"200\",\"0.7\",\"0.9461\",\"0.9135\"])\n",
    "print(pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "2akLw78J5zR8",
    "outputId": "d6b58b07-81ab-4e14-cdd1-aca7e81c5ca9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+--------------------+\n",
      "|         Model          |   test accuracy    |\n",
      "+------------------------+--------------------+\n",
      "| Divide and conquer CNN | 0.9314557176789956 |\n",
      "+------------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "pt=PrettyTable()\n",
    "pt.field_names=[\"Model\",\"test accuracy\"]\n",
    "pt.add_row([\"Divide and conquer CNN\",\"0.9314557176789956\"])\n",
    "print(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XQyMyXsL6zD3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HAR_LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
